{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - beautifulsoup4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    soupsieve-1.9.2            |           py36_0          61 KB  anaconda\n",
      "    openssl-1.1.1              |       h7b6447c_0         5.0 MB  anaconda\n",
      "    beautifulsoup4-4.8.0       |           py36_0         147 KB  anaconda\n",
      "    certifi-2019.6.16          |           py36_1         156 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    soupsieve:      1.9.2-py36_0      anaconda   \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    beautifulsoup4: 4.6.3-py37_0                  --> 4.8.0-py36_0     anaconda\n",
      "    certifi:        2019.6.16-py36_1  conda-forge --> 2019.6.16-py36_1 anaconda\n",
      "    openssl:        1.1.1c-h516909a_0 conda-forge --> 1.1.1-h7b6447c_0 anaconda\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "soupsieve-1.9.2      | 61 KB     | ##################################### | 100% \n",
      "openssl-1.1.1        | 5.0 MB    | ##################################### | 100% \n",
      "beautifulsoup4-4.8.0 | 147 KB    | ##################################### | 100% \n",
      "certifi-2019.6.16    | 156 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# Install beautifulsoup4\n",
    "!conda install -c anaconda beautifulsoup4 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - geocoder\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.6.16          |           py36_1         149 KB  conda-forge\n",
      "    future-0.17.1              |        py36_1000         701 KB  conda-forge\n",
      "    click-7.0                  |             py_0          61 KB  conda-forge\n",
      "    ratelim-0.1.6              |             py_2           6 KB  conda-forge\n",
      "    geocoder-1.38.1            |             py_1          53 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         970 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    future:   0.17.1-py36_1000 conda-forge\n",
      "    geocoder: 1.38.1-py_1      conda-forge\n",
      "    ratelim:  0.1.6-py_2       conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:  2019.6.16-py36_1 anaconda    --> 2019.6.16-py36_1  conda-forge\n",
      "    click:    6.7-py37_0                   --> 7.0-py_0          conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    openssl:  1.1.1-h7b6447c_0 anaconda    --> 1.1.1c-h516909a_0 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2019.6.16    | 149 KB    | ##################################### | 100% \n",
      "future-0.17.1        | 701 KB    | ##################################### | 100% \n",
      "click-7.0            | 61 KB     | ##################################### | 100% \n",
      "ratelim-0.1.6        | 6 KB      | ##################################### | 100% \n",
      "geocoder-1.38.1      | 53 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# Install geocoder package\n",
    "!conda install -c conda-forge geocoder --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - lxml\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    lxml-4.4.1                 |   py36h7ec2d77_0         1.6 MB  conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    lxml: 4.2.5-py37hefd8a0e_0 --> 4.4.1-py36h7ec2d77_0 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "lxml-4.4.1           | 1.6 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge lxml --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: - "
     ]
    }
   ],
   "source": [
    "# Install geopy\n",
    "!conda install -c conda-forge geopy --yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data soruce -1 : List of Boroughs in London from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the web page and get the tables on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_text = requests.get('https://en.wikipedia.org/wiki/List_of_London_boroughs').text\n",
    "soup = BeautifulSoup(website_text, 'xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the raw table inside that webpage\n",
    "tables = soup.find_all('table', {'class':'wikitable sortable'})\n",
    "#print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough_table_1 = pd.read_html(str(tables[0]), index_col=None, header=0)[0]\n",
    "df_borough_table_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough_table_1.rename(columns={'Population (2013 est)[1]':'Population'}, inplace=True)\n",
    "df_borough_table_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough_table_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the second table \n",
    "df_borough_table_2 = pd.read_html(str(tables[1]), index_col=None, header=0)[0]\n",
    "df_borough_table_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough_table_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough_table_2.columns = ['Borough','Inner','Status','Local authority','Political control',\n",
    "                         'Headquarters','Area (sq mi)','Population','Co-ordinates','Nr. in map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs = df_borough_table_1.append(df_borough_table_2, ignore_index = True) \n",
    "df_London_boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_crime_data_link = 'https://data.london.gov.uk/download/recorded_crime_summary/d2e9ccfc-a054-41e3-89fb-53c2bc3ed87a/MPS%20Borough%20Level%20Crime%20%28most%20recent%2024%20months%29.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data = pd.read_csv(London_crime_data_link)\n",
    "\n",
    "df_london_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data.rename(columns={'LookUp_BoroughName':'Borough', 'MajorText':'MajorCrimeCategory', 'MinorText':'MinorCrimeCategory'}, inplace=True)\n",
    "df_london_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data['MajorCrimeCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data['24months_Total'] = df_london_crime_data.sum(axis=1)\n",
    "df_london_crime_data['24months_Mean'] = df_london_crime_data.mean(axis=1)\n",
    "df_london_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_crime_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_pivot_london_crime_data = pd.pivot_table(df_london_crime_data, values=['24months_Total'],\n",
    "                               index=['Borough'],\n",
    "                               columns=['MajorCrimeCategory'],\n",
    "                               aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "df_pivot_london_crime_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data['Total_Crimes_in_Borough'] = df_pivot_london_crime_data.sum(axis=1)\n",
    "df_pivot_london_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.columns = ['Borough', 'Arson and Criminal Damage', 'Burglary', 'Drug Offences', 'Miscellaneous Crimes Against Society',\n",
    "                                        'Possession of Weapons', 'Public Order Offences', 'Robbery', 'Sexual Offences', 'Theft',\n",
    "                                        'Vehicle Offences', 'Violence Against the Person', 'Total_Crimes_in_Borough']\n",
    "df_pivot_london_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_london_crime_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_London_boroughs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both the Borough columns have same Borough names\n",
    "(df_London_boroughs['Borough'] == df_pivot_london_crime_data['Borough']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['ColumnName'].isin(df2['ColumnName']).value_counts()\n",
    "df_London_boroughs['Borough'].isin(df_pivot_london_crime_data['Borough']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_London_boroughs['Borough']) - set(df_pivot_london_crime_data['Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_pivot_london_crime_data['Borough']) - set(df_London_boroughs['Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['BrandName'].replace(['ABC', 'AB'], 'A')\n",
    "df_London_boroughs['Borough'].replace('Barking and Dagenham [note 1]', 'Barking and Dagenham', inplace=True)\n",
    "df_London_boroughs['Borough'].replace('Greenwich [note 2]', 'Greenwich', inplace=True)\n",
    "df_London_boroughs['Borough'].replace('Hammersmith and Fulham [note 4]', 'Hammersmith and Fulham', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_London_boroughs['Borough']) - set(df_pivot_london_crime_data['Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_London_boroughs['Borough']).intersection(set(df_pivot_london_crime_data['Borough']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_London_boroughs['Borough'].equals(df_pivot_london_crime_data['Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = pd.DataFrame()\n",
    "df_temp1 =pd.merge(df_London_boroughs, df_pivot_london_crime_data, on=['Borough'], how='outer', validate=\"one_to_one\")\n",
    "df_temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1['Borough']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_london_data = df_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_london_data.sort_values(['Total_Crimes_in_Borough'], ascending = False, axis = 0, inplace = True )\n",
    "\n",
    "df_topCrimes_borough_10 = df_combined_london_data.head(10) \n",
    "df_topCrimes_borough_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the inline \n",
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "# check for latest version of Matplotlib\n",
    "print ('Matplotlib version: ', mpl.__version__) # >= 2.0.0\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "#import matplotlib.cm as cm\n",
    "#import matplotlib.colors as colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plotdata = df_topCrimes_borough_10[['Borough','Total_Crimes_in_Borough']]\n",
    "\n",
    "df_plotdata.set_index('Borough', inplace = True)\n",
    "\n",
    "ax = df_plotdata.plot(kind='bar', figsize=(20, 10), rot=0)\n",
    "\n",
    "ax.set_ylabel('Total Number of Crimes in 24 monthss') # add to Y-label to the plot\n",
    "ax.set_xlabel('Borough') # add X-label to the plot\n",
    "ax.set_title('Boroughs with highest number of crimes in London') # title\n",
    "\n",
    "# Creating a function to display the percentage.\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(), decimals=2), \n",
    "                (p.get_x()+p.get_width()/2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize = 12\n",
    "               )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_london_data.sort_values(['Total_Crimes_in_Borough'], ascending = True, axis = 0, inplace = True )\n",
    "\n",
    "df_leastCrimes_borough_10 = df_combined_london_data.head(10) \n",
    "df_leastCrimes_borough_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plotdata = df_leastCrimes_borough_10[['Borough','Total_Crimes_in_Borough']]\n",
    "\n",
    "df_plotdata.set_index('Borough', inplace = True)\n",
    "\n",
    "ax = df_plotdata.plot(kind='bar', figsize=(20, 10), rot=0, color='green')\n",
    "\n",
    "ax.set_ylabel('Total Number of Crimes in 24 monthss') # add to Y-label to the plot\n",
    "ax.set_xlabel('Borough') # add X-label to the plot\n",
    "ax.set_title('Boroughs with Leastt number of crimes in London') # title\n",
    "\n",
    "# Creating a function to display the percentage.\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(), decimals=2), \n",
    "                (p.get_x()+p.get_width()/2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize = 12\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leastCrimes_borough_10[['Borough', 'Total_Crimes_in_Borough']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore 'Heathrow and London City Airports', as these are airport areas. \n",
    "Let us consider next Top three boroughs for further study/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_london_boroughs = df_leastCrimes_borough_10.head(4)\n",
    "df_best_london_boroughs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_london_boroughs = df_best_london_boroughs[df_best_london_boroughs.Borough != 'London Heathrow and London City Airports']\n",
    "df_best_london_boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect list of neighbourhoods for the three best boroughs with least number of crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sutton_neighbourhood = ['Bandon Hill', 'Beddington', 'Beddington Corner', 'Belmont', 'Benhilton', 'Carshalton',\n",
    "                            'Carshalton Beeches', 'Carshalton on the Hill', 'Cheam', 'Hackbridge', \n",
    "                            'Little Woodcote', 'North Cheam', 'Rosehill', 'St. Helier', 'South Beddington',\n",
    "                            'Sutton principal town',  'Sutton Common', 'Sutton High Street','The Wrythe',\n",
    "                            'Wallington', 'Woodcote Green', 'Worcester Park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Richmond_upon_Thames_neighbourhood = ['Barnes', 'East Sheen', 'Ham and Petersham', 'Hampton', 'Hampton Hill',\n",
    "                                        'Hampton Wick', 'Kew', 'Mortlake', 'Richmond and Richmond Hill',\n",
    "                                        'Strawberry Hill', 'St Margarets and East Twickenham', 'Teddington',\n",
    "                                        'Twickenham', 'Whitton and Heathfield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kingston_upon_Thames_neighbourhood = ['Berrylands', 'Canbury', 'Chessington', 'Coombe', 'Hook', \n",
    "                                          'Kingston upon Thames', 'Kingston Vale', 'Malden Rushett', \n",
    "                                          'Motspur Park', 'New Malden', 'Norbiton', 'Old Malden', 'Hampton Wick',\n",
    "                                          'Surbiton', 'Tolworth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Neighbourhood', 'Latitude', 'Longitude']\n",
    "lst = []\n",
    "\n",
    "for index_neighbourhood in Kingston_upon_Thames_neighbourhood:\n",
    "    #print(index_neighbourhood)\n",
    "    address = '{},London,United Kingdom'.format(index_neighbourhood)\n",
    "    #print (address)\n",
    "    geolocator = Nominatim(user_agent=\"London_agent\")\n",
    "    location = geolocator.geocode(address)\n",
    "    #Latitude.append(location.latitude)\n",
    "    #Longitude.append(location.longitude)\n",
    "    \n",
    "    lst.append([index_neighbourhood, location.latitude, location.longitude])\n",
    "    #print(index_neighbourhood, location.latitude, location.longitude)\n",
    "    \n",
    "df_KUT_borough_1 = pd.DataFrame(lst, columns=cols)\n",
    "df_KUT_borough_1.head()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KUT_borough_1['Borough'] = 'Kingston upon Thames'\n",
    "df_KUT_borough_1.reset_index(inplace = True)\n",
    "df_KUT_borough_1.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Neighbourhood', 'Latitude', 'Longitude']\n",
    "lst = []\n",
    "\n",
    "for index_neighbourhood in Sutton_neighbourhood:\n",
    "    #print(index_neighbourhood)\n",
    "    address = '{},London,United Kingdom'.format(index_neighbourhood)\n",
    "    #print (address)\n",
    "    geolocator = Nominatim(user_agent=\"London_agent-1\")\n",
    "    location = geolocator.geocode(address)\n",
    "    #print (location)\n",
    "    #Latitude.append(location.latitude)\n",
    "    #Longitude.append(location.longitude)\n",
    "    if (location != None):\n",
    "        lst.append([index_neighbourhood, location.latitude, location.longitude])\n",
    "        #print(index_neighbourhood, location.latitude, location.longitude)\n",
    "    \n",
    "    \n",
    "df_Sutton_borough_1 = pd.DataFrame(lst, columns=cols)\n",
    "df_Sutton_borough_1.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Sutton_borough_1['Borough'] = 'Sutton'\n",
    "df_Sutton_borough_1.reset_index(inplace = True)\n",
    "df_Sutton_borough_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Neighbourhood', 'Latitude', 'Longitude']\n",
    "lst = []\n",
    "\n",
    "for index_neighbourhood in Richmond_upon_Thames_neighbourhood:\n",
    "    #print(index_neighbourhood)\n",
    "    address = '{},London,United Kingdom'.format(index_neighbourhood)\n",
    "    #print (address)\n",
    "    geolocator = Nominatim(user_agent=\"London_agent-1\")\n",
    "    location = geolocator.geocode(address)\n",
    "    #print (location)\n",
    "    #Latitude.append(location.latitude)\n",
    "    #Longitude.append(location.longitude)\n",
    "    if (location != None):\n",
    "        lst.append([index_neighbourhood, location.latitude, location.longitude])\n",
    "        #print(index_neighbourhood, location.latitude, location.longitude)\n",
    "    \n",
    "    \n",
    "df_RichmondUT_borough_1 = pd.DataFrame(lst, columns=cols)\n",
    "df_RichmondUT_borough_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RichmondUT_borough_1['Borough'] = 'Richmond upon Thames'\n",
    "df_RichmondUT_borough_1.reset_index(inplace = True)\n",
    "df_RichmondUT_borough_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods = pd.DataFrame(columns =['Neighbourhood', 'Latitude', 'Longitude' 'Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods = df_london_best_neighbourhoods.append(df_KUT_borough_1)\n",
    "df_london_best_neighbourhoods.reset_index(inplace = True)\n",
    "df_london_best_neighbourhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods = df_london_best_neighbourhoods.append(df_Sutton_borough_1)\n",
    "#df_london_best_neighbourhoods.reset_index(inplace = True)\n",
    "df_london_best_neighbourhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods = df_london_best_neighbourhoods.append(df_RichmondUT_borough_1)\n",
    "#df_london_best_neighbourhoods.reset_index(inplace = True)\n",
    "df_london_best_neighbourhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'London, United Kingdom'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"london_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of London are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of London using latitude and longitude values\n",
    "map_london_best_neighbourhoods = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(df_london_best_neighbourhoods['Latitude'], df_london_best_neighbourhoods['Longitude'], \n",
    "                                               df_london_best_neighbourhoods['Borough'], df_london_best_neighbourhoods['Neighbourhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_london_best_neighbourhoods)  \n",
    "    \n",
    "map_london_best_neighbourhoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLIENT_ID = 'your-client-ID' # your Foursquare ID\n",
    "#CLIENT_SECRET = 'your-client-secret' # your Foursquare Secret\n",
    "CLIENT_ID = 'RMWJOO4Y0BHSN4HGFU0A2LEPGTP5FBQED5BOP0Z1CEJNBFIQ' # your Foursquare ID\n",
    "CLIENT_SECRET = 'DT1FEELYFNOTFBUQ3RMGLWDEPI2LNQ52NROYFIZMXQTUJ2FT' # your Foursquare Secret\n",
    "\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your answer here\n",
    "\n",
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 500 # define radius\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_best_venues = getNearbyVenues(names=df_london_best_neighbourhoods['Neighbourhood'],\n",
    "                                   latitudes=df_london_best_neighbourhoods['Latitude'],\n",
    "                                   longitudes=df_london_best_neighbourhoods['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the size of the resulting dataframe\n",
    "print(london_best_venues.shape)\n",
    "london_best_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_best_venues.groupby('Neighbourhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out how many unique categories can be curated from all the returned venues\n",
    "print('There are {} uniques categories.'.format(len(london_best_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "london_best_venues_onehot = pd.get_dummies(london_best_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "london_best_venues_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add neighborhood column back to dataframe\n",
    "london_best_venues_onehot['Neighbourhood'] = london_best_venues['Neighbourhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [london_best_venues_onehot.columns[-1]] + list(london_best_venues_onehot.columns[:-1])\n",
    "london_best_venues_onehot = london_best_venues_onehot[fixed_columns]\n",
    "\n",
    "london_best_venues_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_best_venues_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category\n",
    "london_best_grouped = london_best_venues_onehot.groupby('Neighbourhood').mean().reset_index()\n",
    "london_best_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_best_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's print each neighborhood along with the top 5 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in london_best_grouped['Neighbourhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = london_best_grouped[london_best_grouped['Neighbourhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's put that into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to sort the venues in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the new dataframe and display the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighbourhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighbourhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighbourhoods_venues_sorted['Neighbourhood'] = london_best_grouped['Neighbourhood']\n",
    "\n",
    "for ind in np.arange(london_best_grouped.shape[0]):\n",
    "    neighbourhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(london_best_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighbourhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run k-means to cluster the neighborhood into 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "london_grouped_clustering = london_best_grouped.drop('Neighbourhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(london_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighbourhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_best_neighbourhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged = df_london_best_neighbourhoods[['Neighbourhood', 'Borough', 'Latitude', 'Longitude']]\n",
    "\n",
    "# merge london_merged data with london best neighbourhoods to add latitude/longitude for each neighborhood\n",
    "london_merged = london_merged.join(neighbourhoods_venues_sorted.set_index('Neighbourhood'), on='Neighbourhood')\n",
    "\n",
    "#london_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged['Cluster Labels'] = london_merged['Cluster Labels'].astype(int)\n",
    "london_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged = london_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(london_merged['Latitude'], london_merged['Longitude'], london_merged['Neighbourhood'], london_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=8,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster-1)],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster-1)],\n",
    "        fill_opacity=0.5).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories, then assign a name to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster -1\n",
    "london_merged[london_merged['Cluster Labels'] == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster -2\n",
    "london_merged[london_merged['Cluster Labels'] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster -3\n",
    "london_merged[london_merged['Cluster Labels'] == 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster -4\n",
    "london_merged[london_merged['Cluster Labels'] == 3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster -5\n",
    "london_merged[london_merged['Cluster Labels'] == 4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
